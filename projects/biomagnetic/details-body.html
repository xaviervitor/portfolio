<p>
    Biomagnetic a First-Person Puzzle game about using magnetism to pull and hold heavy and far away
    objects to solve small puzzles. The character controller consists of standard object holding
    mechanics, inspired by the half-life 2's pickup physics and the gravity gun. At first, the
    player can only hold small and close objects to get around the level, but once the player gets
    the Magnetic Bracelet, the core mechanic opens more possibilities. It can be played with
    Mouse/Keyboard or a Gamepad.
</p>
<h2>Context</h2>
<p>
    This was my final project for the CS50's Introduction to Game Development. The article below was
    written as part of the project's assignment. It follows a linear path to explain what I made,
    where I struggled and how I solved these problems. The next section contains this article.
</p>
<p>
    Thank you for reviewing and grading all my projects, and many thanks to all the people at
    Harvard for making this amazing course possible.
</p>
<h2>First commit - Initial player movement, level blocking and pickup/hold/throw interactions</h2>
<p>
    First, included assets "Starter Assets - First Person Character Controller", the new default
    unity character controller, to get the basis of a basic first person character controller and
    "Gridbox Prototype Materials", just for prototyping the level in distinct material colors.
</p>
<p>
    After that, I made the initial level blocking. I'm envisioning a game where you can push, pull,
    hold and throw heavy objects using a "magnet hand", so I decided to start implementing a basic
    hold object interaction.
</p>
<p>
    I implemented the "Interaction" button, which allows the player to pick up and drop objects in
    the "Pickable" physics layer in the level, implemented in the
    <span class="code-text">PlayerInteract.cs</span> script. I had to watch some tutorials, read
    the new Unity Input System documentation and also read the default
    <span class="code-text">FirstPersonController.cs</span> code as a base to grasp how the new
    input system works and how to implement a basic button click.
</p>
<p>
    Then, I placed cubes with Rigidbodies to be picked up by the player in the level, and modified
    the Character Controller's Player Input component Behavior to "Invoke Unity Events" instead of
    "Send Messages" to have more control of the input phase received. Initially, when I clicked the
    left mouse button to pickup an object it would pick and throw the object repeatedly about ~20
    times per click. I discovered that the reason was the click input was being read as "performed"
    every frame, and changing this behaviour gave me more control of the phase of the inputs. In the
    end, that didn't solve the problem fully and I ended up detecting the player input using the
    variable <span class="code-text">_input.interact</span>, and storing the value read at the
    previous frame in the variable <span class="code-text">isLeftMouseDown</span>, using it to
    create logic to run the pickup code only once. I decided to keep the Player Input component
    Behavior in case some other situation requires this control over the input phases.
</p>
<p>
    When the left mouse button is clicked, a Raycast is created to detect objects in the distance of
    2 units of the center of the player camera transform. 
</p>
<p>
    As it is, the "First Person Character Controller" made by Unity rotates the
    <span class="italic-text">PlayerCameraRoot</span> - which the
    <span class="italic-text">MainCamera</span> ultimately follows - in the Y axis to make the
    character look up and down and rotates the Capsule itself in the X axis to look left and right.
    This is great because it means that if a player model replaces the Capsule it will rotate the
    same as the camera horizontally. The problem is that because of that logic, neither Capsule
    rotation nor <span class="italic-text">PlayerCameraRoot</span> rotation truly represents the
    player forward looking direction. This is why I included a empty
    <span class="italic-text">PlayerRotationReference</span> GameObject inside the PlayerCapsule,
    which is always updated with the current Y rotation of the camera and X rotation of the capsule
    in the <span class="code-text">CameraRotation()</span> function of the
    <span class="code-text">FirstPersonController.cs</span> file. This simplifies code and
    makes this a Player Rotation Reference accessible for possible future uses.
</p>
<p>
    With that, I now have a character controller, a basic "greybox" level and a pickup / throw
    interaction.
</p>
<h2>
    Second commit - Object distance controls, ground indicator, held object follow with Force,
    preservation of momentum and crosshair
</h2>
<p>
    My first idea for improvement of the player controls was to give the player control of the
    distance between the camera and the held object, to give more control of where the player can
    move a magnetic object. Thinking of that, I made the ground indicator, an object that follows
    the held object and raycasts below it to indicate where the nearest ground the object would fall
    if it is dropped.
</p>
<p>
    After that, I implemented the distance controls, and wanted to make the held object be more
    dynamic and react to the physics in a more realistic way. To do that, I had to solve a problem
    that I avoided in the last commit. Previously, I was just parenting the held object to the
    player camera rotation object, meaning that the object didn't use any Force to move to its
    target position, which in turn means that when the object is released, there aren't any forces
    applied to its Rigidbody.
</p>
<p>
    My idea was to calculate the direction vector that would lead to the target position and move
    the object along that vector every <span class="code-text">FixedUpdate</span>, using a force
    based in the current distance from the target position. This implementation only worked after I
    changed the Drag property of every held object to 20, in the
    <span class="code-text">HeldObject.Pickup()</span>, and made the gameplay finally work the
    way I intended, now the velocity of the object is preserved when the player releases it.
</p>
<p>
    I had to learn how Rigidbodies behave and the nuances of
    <span class="code-text">FixedUpdate</span>, <span class="code-text">Update</span> and
    <span class="code-text">LateUpdate</span> to achieve the smooth movement of the held object
    following the player, as well as the <span class="italic-text">Ground Indicator</span> following
    the held object.
</p>
<p>
    Misc:
    <ul>
        <li>
            Added a Crosshair to the center of the HUD and the
            <span class="code-text">UpdateCrosshairColor.cs</span> script, which checks if the
            PlayerInteract script flagged a object in range for the player to pickup and updates
            the color of the crosshair accordingly;
        </li>
        <li>
            Cleaned up code of the held object, which now lives in the HeldObject class, and the
            PlayerInteract script now only holds a HoldObject instance when a object is picked up,
            simplifying the script;
        </li>
        <li>
            Downloaded a new shader, "GhostlyHand", from the asset store, which is being used to
            render the new Held Object Ground Indicator;
        </li>
        <li>
            Moved the StarterAssets folder to the Thirdparty folder to be organized in the same
            folder as the other tools from the asset store.
        </li>
    </ul>
</p>
<h2>
    Third commit - Level almost done, new textures, gamepad control fixes, text tutorial system,
    magnetic enabling item, player progression storage, breakable glasses, secondary interaction,
    button and gate programming, fixed objects passing through walls, miscellaneous fixes    
</h2>
<p>
    Now with the character interaction almost ready and refined in the test level, it is time to
    make the real Level and refine the controller for the necessities of the final game.
</p>
<p>
    I designed a level that first teaches the controls (movement / mouse look / interact / jump) and
    introduces the mechanic of picking objects to solve small puzzles. To show the controls to the
    player, I created the <span class="code-text">ShowTextTutorial.cs</span> script that shows
    and hides text in the canvas coordinating with other instances of the script. If a new trigger
    is activated and a new message has to be shown, the text is overwritten. To make sure the new
    text stays at the screen for the correct time, all the "hide" timers first check if the message
    present in the <span class="italic-text">Canvas</span> is the current message before hiding it.
    The message also is updated when the input method is changed. There are messages for the
    Mouse/Keyboard input and for the Gamepad input. 
</p>
<p>
    I made a "tower" puzzle, in which the player has to remove objects from its base to pickup the
    <span class="italic-text">Magnet Bracelet</span> item and get to the next room. To make the
    tower segment I had to put constraints in the X and Z position, X, Y, and Z rotation, in all the
    interactable objects (all the boxes) and make a script that removes the constraints when the
    player picks up the object, to get around a limitation of Unity's physics engine regarding
    stacking objects. Without the constraints, all the objects would interact and the boxes would
    drift to the sides and fall of the platforms of the puzzle. As I understand, this problem could
    be solved by increasing the <span class="italic-text">Default Solver Iterations</span> option in
    the project settings, but this would have a high performance cost.
</p>
<p>
    The <span class="italic-text">Magnetic Bracelet</span> is just a object that I modeled using the
    ProBuilder tools, Standard Unity Shader and a Light source, with a simple script that uses Lerp
    to do some effects (light dimming and platform translation) and changes a variable in the
    <span class="code-text">PlayerProgression.cs</span> static class, that acts like
    <span class="italic-text">Singleton</span> and stores this piece of player progression. My plan
    is to also use this class to store checkpoints when the player goes through certain areas. 
</p>
<p>
    After the the magnet mechanic is introduced, I made a broken glass wall that breaks when a
    object with a set speed goes through its collision box. I created the model in blender using a
    add-on called "Cell Fracture" that creates cuts procedurally, and imported to Unity adding
    Rigidbodies to all the pieces. Initially they have all the position / rotation constraints set
    as true and Mass with the value of 1. Then I created a script to react to the trigger collision
    and attached to the <span class="italic-text">parent</span> of every glass in the level. When a
    rigidbody with a velocity greater than 10 is detected in the box collider of this
    <span class="italic-text">parent</span> GameObject, the constraints of all child objects are
    removed and the Mass of the glass pieces is set to 0.01 to simulate glass shattering. For the
    collision effect to work properly, I set the
    <span class="italic-text">Collision Detection Mode</span> to 
    "<span class="italic-text">Continuous Dynamic</span>" in the editor. In the
    <span class="code-text">BreakGlass.cs</span> script, after 2 seconds of the impact, I change
    it to "<span class="italic-text">Discrete</span>" for optimization reasons.
</p>
<p>
    The puzzle after the glass shattering segment has boxes inside a strong glass that have to be
    moved for the stairs leading to the next room to be lowered. This exposed a bug in the character
    interaction script, in which the player could accelerate the held magnetic object
    (using <span class="code-text">Q</span>/<span class="code-text">E</span>) and make it
    pass through walls. This happened because the pull speed towards the target position is
    calculated based in distance, which is calculated using the
    <span class="code-text">playerToObjectDistance</span> variable, and I solved the problem
    creating a Raycast between the "<span class="strong-text">current object position</span>" and
    the "<span class="strong-text">target position</span>", detecting walls and, if present,
    changing the "<span class="strong-text">target position</span>" to be the the detected wall hit
    point and changing the <span class="emphasis-text">playerToObjectDistance</span> to be the
    calculated distance between the player and this new point. That solved the problem for normal
    walls, but considering that all glass walls were marked as "IgnoreRaycast", the object would
    pass through those. I had to not use the "IgnoreRaycast" layer anymore and control the layers
    that get raycasted and those who don't in the Raycast functions. "Glass" is raycasted by the
    <span class="italic-text">Wall Raycast</span> but not raycasted by the
    <span class="italic-text">Interact Raycast</span>, and <s>"BrokenGlass"</s>
    <span class="italic-text">(Edit: now named "IgnoreRaycast", not to be confused with the standard
    "Ignore Raycast" to be applied not only to broken glasses)</span> is not raycasted by any of the
    raycasts, so that the magnetic object could go through the broken glass and activate the
    <span class="code-text">BreakGlass.cs</span> script.
</p>
<p>
    After the stairs, I made a Button / Gate puzzle, but I wanted the button to feel natural and
    have some weight. I scraped the button I made in the first commit and designed another using a
    Rigidbody and applying a Up vector force to be pushed by the weight of the objects and the
    player, adjusting the force based on how much close it is from the unpressed position. If the
    button is only pressed by an small amount, 10% for example, the Up force will be only 10% of the
    <span class="code-text">springForce</span> variable. The player doesn't apply its weight by
    default, so I attached another script, <span class="code-text">PlayerButtonPush.cs</span>,
    borrowing some code from <span class="code-text">BasicRigidBodyPush.cs</span> script, which
    comes with the Unity FirstPersonController package, that applies a force to specified layers
    when a collision is detected. After that I wrote the
    <span class="code-text">GateButton.cs</span> script, that reads a pressed value of a
    <span class="italic-text">Button</span> GameObject and applies a Up force to open the gate /
    stops applying to close the gate. This script also works for the "reversed" gates.
</p>
<p>
    Misc:
    <ul>
        <li>
            Changed the <span class="italic-text">Default Max Depenetration Velocity</span> to
            <span class="code-text">1000</span> to prevent objects at high speeds from passing
            through walls;
        </li>
        <li>
            Made a script that slowly changes the Sun direction (rotation) to better frame the first
            red door, as it is completely in the shadows in the starting sun position, without
            losing the first room illumination of the Green Ramp and the Blue Cube;
        </li>
        <li>
            Created the final Materials, using the Normal Map from the Unity First Person
            Controller,
            <span class="code-text">Assets\Thirdparty\StarterAssets\Environment\Art\Textures\Grid_01_Normal.png</span>
            and adding colors based off Gridbox Prototype Materials;
        </li>
        <li>
            Changed the code that makes materials transparent when held, to work with textured
            materials and materials with only flat colors. There are multiple parameters that have
            to be set to change a material Rendering Mode in scripting, and I found a forum post by
            the user "berkhulagu" detailing which ones to set;
        </li>
        <li>
            Changed the gamepad controls to be more intuitive, adding the secondary input hold
            objects maintaining their distance from the player as opposed to being attracted
            immediately;
        </li>
        <li>
            Changed the Camera FOV to 80, and tweaked the default
            <span class="code-text">playerToObjectDistance</span> to match;
        </li>
        <li>
            Implemented a lower limit to the <span class="code-text">playerToObjectDistance</span>,
            as the player should not be able to control the held object behind himself;
        </li>
        <li>
            Fixed a bug where if the ground indicator was too close to the ground, it would not
            detect it and set its size to a big value and not render correctly;
        </li>
        <li>
            Made an animation using the Lerp function to turn off the
            <span class="italic-text">Magnetic Bracelet</span> light and move the
            <span class="italic-text">Altar</span> down when the player picks the
            <span class="italic-text">Bracelet</span> up.
        </li>
    </ul>
</p>
<h2>
    Fourth commit - Switch to URP, level complete, Start and End Scenes, scene transitions,
    respawn/checkpoint scripts, pause menu, light baking, miscellaneous changes
</h2>
<p>
    For the fourth and last commit, I wanted to experiment with the lighting, materials, skyboxes,
    reflections, post-processing and everything related to graphics. To do that, I learned that the
    new rendering pipelines <span class="italic-text">URP</span> and
    <span class="italic-text">HDRP</span> are more suitable and modern in their design, and made the
    switch to the Universal Rendering Pipeline.
</p>
<p>
    After installing, configuring and converting all the materials from the
    <span class="italic-text">Built-in Rendering Pipeline</span> to the
    <span class="italic-text">URP</span>, I could setup the Post-Processing and the Tonemapper. I
    also had to remove the "GhostlyHand" shader addon dependency as it was not working with URP and
    replaced it with new materials using the standard URP Lit Shader, which surprisingly translated
    the visuals very well.
</p>
<p>
    With all the graphics working again, I took the opportunity to try to solve a problem that has been
    haunting me since the start of the project, in that the Ground Indicator would render inside a
    transparent Held Object. I found a solution in an old, archived Unity Wiki tutorial. It involves
    using a Shader Pass to write in the <span class="italic-text">Depth Buffer</span>, which the
    Ground Indicator shader Lit material would not draw, since it would think the parts of the
    Ground Indicator that were inside the Held Object would be behind it. The resource I used was
    archived at 
    <a href="https://web.archive.org/web/20210831213650/http://wiki.unity3d.com:80/index.php/DepthMask">
        DepthMask by Neil Carter (NCarter) and Daniel Brauer (Danielbrauer) 
    </a>.
</p>
<p>
    Then, I started making the last room, with a puzzle to activate a machine (internally called the
    "Portal") capable of teleporting the player to another scene, the end of the game. I wrote a
    small script to make the machine doors, scene load and animation all work as I intended, called
    <span class="code-text">OpenPortalDoor.cs</span> and made all Button's Trails emit light when
    activated, for them to "pop" in this dark room.
</p>
<p>
    To make the game end scene, I used a simple idea I had at the beginning of the development, a
    zero gravity "Jenga" tower. I made a <span class="code-text">SpawnJenga.cs</span> that spawns
    two towers in different sizes at the scene, using two separate prefabs to avoid prefab scaling
    bugs. I had to change the <span class="code-text">HeldObject.cs</span> code to work with the
    jenga pieces in zero gravity. Having made a level scene and the end scene, I made a title /
    start screen, showing a background, the magnetic bracelet, the title of the game and a
    <span class="code-text">"press any button to play"</span> text. I made the background
    configuring a new Procedural Skybox and applying a really strong Bloom effect in the
    Post-Processing stack. As initially the entire scene was being rendered by one single camera,
    the post-processing effects were perfect for the skybox but made the bracelet too bright.
    The solution I found was rendering using a camera to render the skybox with all post-processing
    applied and another camera to render just the bracelet, with the culling mask applied to skip
    rendering the skybox, and use the bracelet render as a Overlay on top of the another skybox
    rendering camera. After that, to give the Start Scene more movement, I made
    <span class="code-text">AnimatePostProcessing.cs</span> to make the bloom change oscillate its
    color and <span class="code-text">AnimateScaleText.cs</span> to make the text oscillate its size
    too. And of course, the <span class="code-text">AnyPressListener.cs</span> script to listen for
    input.
</p>
<p>
    I made a Fade-in / Fade-out transition to scenes, using Coroutines that change an "FadeImage"
    GameObject color's alpha from <span class="strong-text"><span class="code-text">0</span></span>
    to <span class="strong-text"><span class="code-text">1</span></span>, and then loads the new
    Scene.
</p>
<p>
    Because this is a puzzle game, a respawn mechanic was needed in case the player loses an object
    necessary to the solution, and I set out to implement a respawn mechanic. I implemented a script
    named <span class="strong-text">PlayerRespawn.cs</span>, with a function that is called when the
    player presses the <span class="italic-text">Respawn</span> Input, and another similar script,
    <span class="code-text">DeathColliderRespawn.cs</span> which does the same, but when the player
    collides with a collision object. Then I put invisible colliders in the level in certain areas
    to act as checkpoints, that change the <span class="italic-text">checkpointPosition</span> and
    <span class="italic-text">checkpointRotation</span> in the
    <span class="code-text">PlayerProgression.cs</span> script, which was changed from a simple
    static class to a proper GameObject <span class="strong-text">Singleton</span>. The 
    <span class="italic-text">position</span> and <span class="italic-text">rotation</span> are
    always copied to the *Player*'s in the <span class="code-text">PlayerRespawn.cs</span> script in
    the <span class="code-text">Start()</span> function, making the player respawn. A problem I
    faced was that the player would always spawn in the level and the
    <span class="code-text">PlayerRespawn</span> script would try to change its position before the
    <span class="italic-text">Checkpoint</span> variables were set. Other problem was that after the
    variables are set, the singleton would maintain the value even after Unity loaded another level.
    I solved these problems by creating a "firstLoadSpawn" variable, setting its value to
    <span class="code-text">true</span> in every Scene change, and making the first checkpoint
    collider (always in the initial spawn position of the player in every level) wait for a time
    before being active. This way, when the player collides with the checkpoint, I know that them
    were really in the checkpoint location, instead of colliding in one frame and trying to change
    its <span class="italic-text">position</span> or <span class="italic-text">rotation</span>
    before the variable was set.
</p>
<p>
    I also needed to make a Pause menu, to provide another way for the player to Restart the level
    and Quit the game. The easiest way I found to pause the game in Unity is to use the
    <span class="code-text">Time.timeScale</span> variable. There were problems in some animations /
    physics code that weren't bound to <span class="code-text">Time.time</span>, and would continue
    running with the rest of the game paused, and problems with the Inputs and the mouse cursor.
    After fixing these bugs, I started to design a pause overlay. Initially I wanted to make proper
    UI clickable Buttons, but to speed up the process, I decided to just change the Input's Action
    Map and display the buttons that needed to be pressed for every action
    (<span class="italic-text">resume</span>, <span class="italic-text">restart</span> and
    <span class="italic-text">quit</span>) in the pause screen. After mapping the actions to the
    respective functions and reimplementing Coroutines for the Respawn and Quit options, the Pause
    Overlay was done.
</p>
<p>
    The last feature I wanted to implement, and by far the most not antecipated time sink of this
    project was the Lighting process. From the start of this project, I made the scene thinking of
    how the objects in the scene would be lit, and now was the time to do so. Throughout the project
    I experimented with the Unity Lightmapper, and now more than ever. It was really hard to grasp
    which of the settings would affect the speed of the bake, quality of the final calculations and
    by how much. Another process that I didn't fully mastered is the placement and setup of the
    Reflection Probes. There was a learning curve to that as well, but now I understand how the
    Lightmapping works. After some "test-bakes", I tweaked all materials to take advantage of the
    lighting and reflections of the scene and made a final, polished bake. After all that, even
    knowing it isn't perfect, I am satisfied with the end result.
</p>
<p>
    You can play Biomagnetic or check out its source code visiting the links below.
</p>